{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_CNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xROzgyrukN6m"
      },
      "source": [
        "### Dataset \n",
        "\n",
        "The MNIST dataset is one of the most common datasets used for image classification and accessible from many different sources. In fact, even Tensorflow and Keras allow us to import and download the MNIST dataset directly from their API. Therefore, using the following two lines we can import TensorFlow and MNIST dataset under the Keras API.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-N0_JhL7jQ4_",
        "outputId": "86c17652-45ec-4576-a70b-6a00fe23b2c3"
      },
      "source": [
        "import tensorflow as tf\n",
        "#to chack if gpu is activated. If 0, then check the runtime settings of colab\n",
        "print(\"Num of GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num of GPUs Available:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvqNHNk2kqkH"
      },
      "source": [
        "The MNIST database contains 60,000 training images and 10,000 testing images. The inbuilt functions allow to separate them into two groups as train and test. x_train and x_test parts contain greyscale codes (from 0 to 255) while y_train and y_test parts contain labels from 0 to 9 which represents which number they actually are. To visualize these numbers, we can get help from matplotlib.\n",
        "\n",
        "You can set the image_index to be any number between 0 and 60000."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "KsmJm5wKkHUQ",
        "outputId": "48cf95d8-99aa-45ab-b820-378785c9926b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "image_index = 10 \n",
        "print(y_train[image_index]) \n",
        "plt.imshow(x_train[image_index], cmap='Greys')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f5f940059e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6o2c_ntQlYuv"
      },
      "source": [
        "When we run the code above, we will get the greyscale visualization of the RGB codes as shown above. Then, run the below code to get more info about the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cspPjRSNmM-o",
        "outputId": "bad13bd9-e6e3-4b90-ce5c-6c4dd7ec05e1"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S06Sx5XKnAcs"
      },
      "source": [
        "You will get (60000, 28, 28). 60000 represents the number of images in the train dataset and (28, 28) represents the size of the image: 28 x 28 pixel.\n",
        "\n",
        "To be able to use the dataset in Keras API, we need 4-dims NumPy arrays. However, as we see above, our array is 3-dims. In addition, we must normalize our data as it is always required in neural network models. We can achieve this by dividing the RGB codes to 255"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRadqIbhnGig",
        "outputId": "6ba05fa6-8391-4018-ced1-03ea16c17c28"
      },
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "input_shape = (28, 28, 1)\n",
        "# Making sure that the values are float so that we can get decimal points after division\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "# Normalizing the RGB codes by dividing it to the max RGB value.\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('Number of images in x_train', x_train.shape[0])\n",
        "print('Number of images in x_test', x_test.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "Number of images in x_train 60000\n",
            "Number of images in x_test 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-i35zorLoSbr"
      },
      "source": [
        "You can see that the shape of the train dataset changed from (60000, 28, 28) to (60000, 28, 28, 1). The images are also normalized, between the values of 0 and 1.\n",
        "\n",
        "### Defining the Model\n",
        "\n",
        "Next process is to define the structure of the model. We will build our model by using high-level Keras API which uses either TensorFlow or Theano on the backend. We are importing the Sequential Model from Keras and add Conv2D, MaxPooling, Flatten, Dropout, and Dense layers. The important layers are Conv2D, Maxpooling, and Dense layers. In addition, Dropout layers fight with the overfitting by disregarding some of the neurons while training while Flatten layers flatten 2D arrays to 1D arrays before building the fully connected layers.\n",
        "\n",
        "You can experiment with any number for the first Dense layer; however, the final Dense layer must have 10 neurons since we have 10 number classes (0, 1, 2, …, 9). You may always experiment with kernel size, pool size, activation functions, dropout rate, and a number of neurons in the first Dense layer to get a better result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeKjn-GColB8"
      },
      "source": [
        "# Importing the required Keras modules containing model and layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
        "# Creating a Sequential Model and adding the layers\n",
        "model = Sequential()\n",
        "model.add(Conv2D(28, kernel_size=(3,3), input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten()) # Flattening the 2D arrays for fully connected layers\n",
        "model.add(Dense(128, activation=tf.nn.relu))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10,activation=tf.nn.softmax))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eA7nrIAJpxor"
      },
      "source": [
        "### Compiling and Training of the Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRVCddbkp7Mh",
        "outputId": "b0015ed4-4e87-459d-d270-e5d6a2f70cb8"
      },
      "source": [
        "model.compile(optimizer='adam', \n",
        "              loss='sparse_categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "model.fit(x=x_train,y=y_train, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2111 - accuracy: 0.9368\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0864 - accuracy: 0.9737\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0603 - accuracy: 0.9808\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0471 - accuracy: 0.9846\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0362 - accuracy: 0.9882\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0313 - accuracy: 0.9894\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0248 - accuracy: 0.9918\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0235 - accuracy: 0.9921\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0204 - accuracy: 0.9931\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0185 - accuracy: 0.9937\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5f4804a588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTj48ijPqimD"
      },
      "source": [
        "If you want you can change the optimizer, loss function, metrics, and epochs. However, generally the adam optimizer usually out-performs the other optimizers.The epoch number might seem a bit small. However, you will reach to 98–99% test accuracy. \n",
        "\n",
        "### Note\n",
        "Keep in mind when chaning the loss function. We are currently doing a multiclass classification, so we cannot have any loss function working in our case. Here, `sparse_categorical_crossentropy` is used because the last dimension is sparse. Only 1 out of the 10 classes will be `1`, all others are `0`.\n",
        "\n",
        "### Evaluation\n",
        "you can evaluate the trained model with x_test and y_test using one line of code. This step compares the model's accuracy in the test dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGAFBr2Tr59Q",
        "outputId": "b1b127a9-4478-4ae3-e6fe-5fbd03356691"
      },
      "source": [
        "model.evaluate(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 2ms/step - loss: 0.0604 - accuracy: 0.9857\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.06038759648799896, 0.9857000112533569]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEne6UCXsKLa"
      },
      "source": [
        "Thus, we see that our model has got a good accuracy of `98%` in the test dataset."
      ]
    }
  ]
}